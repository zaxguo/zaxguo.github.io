---
title:          "STI: Turbocharge NLP Inference at the Edge via Elastic Pipelining"
date:           2023-01-05 00:01:00 +0800
selected:       true
pub:            "ASPLOS"
pub_date:       "2023"
abstract: >-
  We show how large Transformer models can run on a wimpy, cheap SoC at 1MB of memory while maintaining accuracy. 
cover:          /assets/images/covers/sti.png
authors:
- Liwei Guo
- Wonkyo Choe
- Felix Xiaozhu Lin
links:
  Paper: https://dl.acm.org/doi/pdf/10.1145/3575693.3575698
---